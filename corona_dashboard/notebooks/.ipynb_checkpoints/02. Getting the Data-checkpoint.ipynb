{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Data\n",
    "\n",
    "Our data comes directly from the [John Hopkins COVID-19 Github repository][1], which tracks all deaths and cases from each country in the world as well as many regions within some countries. All of the data needed for this project is within the [time series][2] directory, which contains four CSV files that summarize the deaths and cases for the world and the USA. The repository uses the word \"confirmed\" to refer to cases.\n",
    "\n",
    "[1]: https://github.com/CSSEGISandData/COVID-19\n",
    "[2]: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data into a pandas DataFrame\n",
    "\n",
    "The pandas `read_csv` function can read in remote CSV files by passing it the URL. The exact URL on Github is a bit tricky. You must use the \"raw\" data file, which can be retrieved by clicking on the file name (taking you to the next page), then right-clicking the \"view raw\" or \"download\" button and copying the link. The image below shows the screen you'll see for the first CSV.\n",
    "\n",
    "![1]\n",
    "\n",
    "[1]: images/url_download.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naming conventions\n",
    "\n",
    "Before we write any code, let's cover some naming conventions that we will use throughout the project.\n",
    "\n",
    "### `group`\n",
    "\n",
    "We will use the name `group` to refer to the two separate \"groups\" of data.\n",
    "\n",
    "* `\"world\"` - represents all data from each country\n",
    "* `\"usa\"` - represents all data from each US state\n",
    "\n",
    "### `kind`\n",
    "\n",
    "We will use the name `kind` to refer to the two different kinds of COVID-19 data.\n",
    "\n",
    "* `\"deaths\"`\n",
    "* `\"cases\"`\n",
    "\n",
    "\n",
    "### `area`\n",
    "\n",
    "Occasionally, we will refer to either a specific country or state with the name `area`.\n",
    "\n",
    "## Downloading the data\n",
    "\n",
    "Now that we have the URL, we can download the data with pandas. Complete the exercise below to download all four files as DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function that reads in a single CSV and returns it as a DataFrame. This function accepts a kind and group. Use the variable `DOWNLOAD_URL` in your solution. Make sure you look at the URL in the repo from above to determine what values `kind` and `group` refer to. You'll have to reassign their values in the function so that the URL is correct. For example, the function call `download_data(\"world\", \"deaths\")` should download [one of the files on this page](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DOWNLOAD_URL = (\n",
    "    \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/\"\n",
    "    \"master/csse_covid_19_data/csse_covid_19_time_series/\"\n",
    "    \"time_series_covid19_{kind}_{group}.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "def download_data(group, kind):\n",
    "    \"\"\"\n",
    "    Reads in a single dataset from the John Hopkins GitHub repo\n",
    "    as a DataFrame\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    group : \"world\" or \"usa\"\n",
    "    \n",
    "    kind : \"deaths\" or \"cases\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "    \"\"\"\n",
    "    group = \"US\" if group == \"usa\" else \"global\"\n",
    "    kind = \"confirmed\" if kind == \"cases\" else \"deaths\"\n",
    "    url = DOWNLOAD_URL.format(kind=kind, group=group)\n",
    "    return pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>8/7/22</th>\n",
       "      <th>8/8/22</th>\n",
       "      <th>8/9/22</th>\n",
       "      <th>8/10/22</th>\n",
       "      <th>8/11/22</th>\n",
       "      <th>8/12/22</th>\n",
       "      <th>8/13/22</th>\n",
       "      <th>8/14/22</th>\n",
       "      <th>8/15/22</th>\n",
       "      <th>8/16/22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84001001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.539527</td>\n",
       "      <td>-86.644082</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84001003</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>30.727750</td>\n",
       "      <td>-87.722071</td>\n",
       "      <td>...</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84001005</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>31.868263</td>\n",
       "      <td>-85.387129</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84001007</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.996421</td>\n",
       "      <td>-87.125115</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84001009</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>Blount</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>33.982109</td>\n",
       "      <td>-86.567906</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 950 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UID iso2 iso3  code3    FIPS   Admin2 Province_State Country_Region  \\\n",
       "0  84001001   US  USA    840  1001.0  Autauga        Alabama             US   \n",
       "1  84001003   US  USA    840  1003.0  Baldwin        Alabama             US   \n",
       "2  84001005   US  USA    840  1005.0  Barbour        Alabama             US   \n",
       "3  84001007   US  USA    840  1007.0     Bibb        Alabama             US   \n",
       "4  84001009   US  USA    840  1009.0   Blount        Alabama             US   \n",
       "\n",
       "         Lat      Long_  ... 8/7/22  8/8/22  8/9/22  8/10/22  8/11/22  \\\n",
       "0  32.539527 -86.644082  ...    221     221     221      221      222   \n",
       "1  30.727750 -87.722071  ...    691     691     691      691      693   \n",
       "2  31.868263 -85.387129  ...    101     101     101      101      101   \n",
       "3  32.996421 -87.125115  ...    105     105     105      105      105   \n",
       "4  33.982109 -86.567906  ...    250     250     250      250      251   \n",
       "\n",
       "   8/12/22  8/13/22  8/14/22  8/15/22  8/16/22  \n",
       "0      222      222      222      222      222  \n",
       "1      693      693      693      693      693  \n",
       "2      101      101      101      101      101  \n",
       "3      105      105      105      105      105  \n",
       "4      251      251      251      251      251  \n",
       "\n",
       "[5 rows x 950 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa_deaths = download_data('usa', 'deaths')\n",
    "usa_deaths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important information on exercises - please read!\n",
    "\n",
    "All of the exercises require you to complete the body of a function. All functions end with the `pass` keyword. **Delete** it and write your solution in the body of the function.\n",
    "\n",
    "Solutions for all exercises are found in the [solutions.py](solutions.py) file in this directory. You can open it up in your favorite editor, or just click the link to open it in your browser.\n",
    "\n",
    "In the code cell following each exercise, you will see a single line of code that imports the function from the solutions.py file. For example, `from solutions import download_data`. Running this statement will provide you with a version of the function that produces the correct output for the exercise.\n",
    "\n",
    "**Comment out the import line** if you want to use and test **your version** of the function completed above. I highly recommend completing the exercises on your own. Keep the import line uncommented if you do not attempt the exercise. \n",
    "\n",
    "**Always check the solutions!** Make sure to check the [solutions.py](solutions.py) file for each exercise, even if you are sure you answered it correctly. Verifying solutions is one of the best known methods for internalizing new material."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the `download_data` function\n",
    "\n",
    "Let's read in the world deaths file as a DataFrame and output the head to verify that it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # comment out the import line below if you attempted the exercise above\n",
    "# # keep the line below if you did not attempt the exercise\n",
    "# from solutions import download_data \n",
    "# df_world_deaths = download_data('world', 'deaths')\n",
    "# df_world_deaths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a another function which uses `download_data` to read in all four DataFrames.\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function that reads in all four CSVs as DataFrames returning them in a dictionary. Use the group and kind separated by an underscore as the key (i.e. `\"world_deaths\"`). Use the `GROUPS` and `KINDS` variables in your solution.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPS = \"world\", \"usa\"\n",
    "KINDS = \"deaths\", \"cases\"\n",
    "\n",
    "def read_all_data():\n",
    "    \"\"\"\n",
    "    Read in all four CSVs as DataFrames\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary of DataFrames\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for group in GROUPS:\n",
    "        for kind in KINDS:\n",
    "            data[f'{group}_{kind}'] = download_data(group, kind)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>8/7/22</th>\n",
       "      <th>8/8/22</th>\n",
       "      <th>8/9/22</th>\n",
       "      <th>8/10/22</th>\n",
       "      <th>8/11/22</th>\n",
       "      <th>8/12/22</th>\n",
       "      <th>8/13/22</th>\n",
       "      <th>8/14/22</th>\n",
       "      <th>8/15/22</th>\n",
       "      <th>8/16/22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.93911</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>187442</td>\n",
       "      <td>187685</td>\n",
       "      <td>187966</td>\n",
       "      <td>188202</td>\n",
       "      <td>188506</td>\n",
       "      <td>188704</td>\n",
       "      <td>188820</td>\n",
       "      <td>189045</td>\n",
       "      <td>189343</td>\n",
       "      <td>189477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.15330</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>317514</td>\n",
       "      <td>317681</td>\n",
       "      <td>318638</td>\n",
       "      <td>319444</td>\n",
       "      <td>320086</td>\n",
       "      <td>320781</td>\n",
       "      <td>321345</td>\n",
       "      <td>321804</td>\n",
       "      <td>322125</td>\n",
       "      <td>322837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.03390</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>268254</td>\n",
       "      <td>268356</td>\n",
       "      <td>268478</td>\n",
       "      <td>268584</td>\n",
       "      <td>268718</td>\n",
       "      <td>268866</td>\n",
       "      <td>269008</td>\n",
       "      <td>269141</td>\n",
       "      <td>269269</td>\n",
       "      <td>269381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 942 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat       Long  1/22/20  1/23/20  \\\n",
       "0            NaN    Afghanistan  33.93911  67.709953        0        0   \n",
       "1            NaN        Albania  41.15330  20.168300        0        0   \n",
       "2            NaN        Algeria  28.03390   1.659600        0        0   \n",
       "\n",
       "   1/24/20  1/25/20  1/26/20  1/27/20  ...  8/7/22  8/8/22  8/9/22  8/10/22  \\\n",
       "0        0        0        0        0  ...  187442  187685  187966   188202   \n",
       "1        0        0        0        0  ...  317514  317681  318638   319444   \n",
       "2        0        0        0        0  ...  268254  268356  268478   268584   \n",
       "\n",
       "   8/11/22  8/12/22  8/13/22  8/14/22  8/15/22  8/16/22  \n",
       "0   188506   188704   188820   189045   189343   189477  \n",
       "1   320086   320781   321345   321804   322125   322837  \n",
       "2   268718   268866   269008   269141   269269   269381  \n",
       "\n",
       "[3 rows x 942 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['world_cases'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function to read in all of the data and output the head of two of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to comment out the following line if you attempt the exercise\n",
    "# this is the last exercise with this warning\n",
    "# from solutions import read_all_data\n",
    "# data = read_all_data()\n",
    "# data['world_cases'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['usa_cases'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the data locally\n",
    "\n",
    "Since the raw data must be downloaded from the internet, let's save a copy of our current data to a local folder so that we have access to it immediately at any time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function that accepts a dictionary of DataFrames and a directory name, and writes them to that directory as CSVs using the key as the filename. Pass the `kwargs` to the `to_csv` method.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(data, directory, **kwargs):\n",
    "    \"\"\"\n",
    "    Writes each raw data DataFrame to a file as a CSV\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dictionary of DataFrames\n",
    "\n",
    "    directory : string name of directory to save files i.e. \"data/raw\"\n",
    "    \n",
    "    kwargs : extra keyword arguments for the `to_csv` DataFrame method\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    for name, df in data.items():\n",
    "        df.to_csv(f\"{directory}/{name}.csv\", **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data(data, \"data/raw\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write those DataFrames as CSVs (without their index) to the \"data/raw\" directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from solutions import write_data\n",
    "# write_data(data, \"data/raw\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function similar to `download_data`, but have it read in the local data that we just saved. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_local_data(group, kind, directory):\n",
    "    \"\"\"\n",
    "    Read in one CSV as a DataFrame from the given directory\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    group : \"world\" or \"usa\"\n",
    "    \n",
    "    kind : \"deaths\" or \"cases\"\n",
    "    \n",
    "    directory : string name of directory to save files i.e. \"data/raw\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame    \n",
    "    \"\"\"\n",
    "    return pd.read_csv(f\"{directory}/{group}_{kind}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>8/7/22</th>\n",
       "      <th>8/8/22</th>\n",
       "      <th>8/9/22</th>\n",
       "      <th>8/10/22</th>\n",
       "      <th>8/11/22</th>\n",
       "      <th>8/12/22</th>\n",
       "      <th>8/13/22</th>\n",
       "      <th>8/14/22</th>\n",
       "      <th>8/15/22</th>\n",
       "      <th>8/16/22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84001001</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.539527</td>\n",
       "      <td>-86.644082</td>\n",
       "      <td>...</td>\n",
       "      <td>17605</td>\n",
       "      <td>17605</td>\n",
       "      <td>17605</td>\n",
       "      <td>17605</td>\n",
       "      <td>17723</td>\n",
       "      <td>17723</td>\n",
       "      <td>17723</td>\n",
       "      <td>17723</td>\n",
       "      <td>17723</td>\n",
       "      <td>17723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84001003</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>30.727750</td>\n",
       "      <td>-87.722071</td>\n",
       "      <td>...</td>\n",
       "      <td>62486</td>\n",
       "      <td>62486</td>\n",
       "      <td>62486</td>\n",
       "      <td>62486</td>\n",
       "      <td>63022</td>\n",
       "      <td>63022</td>\n",
       "      <td>63022</td>\n",
       "      <td>63022</td>\n",
       "      <td>63022</td>\n",
       "      <td>63022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84001005</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>Barbour</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>31.868263</td>\n",
       "      <td>-85.387129</td>\n",
       "      <td>...</td>\n",
       "      <td>6382</td>\n",
       "      <td>6382</td>\n",
       "      <td>6382</td>\n",
       "      <td>6382</td>\n",
       "      <td>6453</td>\n",
       "      <td>6453</td>\n",
       "      <td>6453</td>\n",
       "      <td>6453</td>\n",
       "      <td>6453</td>\n",
       "      <td>6453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84001007</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>Bibb</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>32.996421</td>\n",
       "      <td>-87.125115</td>\n",
       "      <td>...</td>\n",
       "      <td>6996</td>\n",
       "      <td>6996</td>\n",
       "      <td>6996</td>\n",
       "      <td>6996</td>\n",
       "      <td>7070</td>\n",
       "      <td>7070</td>\n",
       "      <td>7070</td>\n",
       "      <td>7070</td>\n",
       "      <td>7070</td>\n",
       "      <td>7070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84001009</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>Blount</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>US</td>\n",
       "      <td>33.982109</td>\n",
       "      <td>-86.567906</td>\n",
       "      <td>...</td>\n",
       "      <td>16095</td>\n",
       "      <td>16095</td>\n",
       "      <td>16095</td>\n",
       "      <td>16095</td>\n",
       "      <td>16209</td>\n",
       "      <td>16209</td>\n",
       "      <td>16209</td>\n",
       "      <td>16209</td>\n",
       "      <td>16209</td>\n",
       "      <td>16209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 949 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UID iso2 iso3  code3    FIPS   Admin2 Province_State Country_Region  \\\n",
       "0  84001001   US  USA    840  1001.0  Autauga        Alabama             US   \n",
       "1  84001003   US  USA    840  1003.0  Baldwin        Alabama             US   \n",
       "2  84001005   US  USA    840  1005.0  Barbour        Alabama             US   \n",
       "3  84001007   US  USA    840  1007.0     Bibb        Alabama             US   \n",
       "4  84001009   US  USA    840  1009.0   Blount        Alabama             US   \n",
       "\n",
       "         Lat      Long_  ... 8/7/22  8/8/22  8/9/22  8/10/22  8/11/22  \\\n",
       "0  32.539527 -86.644082  ...  17605   17605   17605    17605    17723   \n",
       "1  30.727750 -87.722071  ...  62486   62486   62486    62486    63022   \n",
       "2  31.868263 -85.387129  ...   6382    6382    6382     6382     6453   \n",
       "3  32.996421 -87.125115  ...   6996    6996    6996     6996     7070   \n",
       "4  33.982109 -86.567906  ...  16095   16095   16095    16095    16209   \n",
       "\n",
       "   8/12/22  8/13/22  8/14/22  8/15/22  8/16/22  \n",
       "0    17723    17723    17723    17723    17723  \n",
       "1    63022    63022    63022    63022    63022  \n",
       "2     6453     6453     6453     6453     6453  \n",
       "3     7070     7070     7070     7070     7070  \n",
       "4    16209    16209    16209    16209    16209  \n",
       "\n",
       "[5 rows x 949 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa_cases = read_local_data('usa', 'cases', 'data/raw')\n",
    "usa_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from solutions import read_local_data\n",
    "# read_local_data('world', 'deaths', 'data/raw').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Write a function similar to `read_all_data`, but have it read in all of the local data that we just saved. The function name is `run` since we will be slowly adding all of our data cleaning and transformation steps to it in the next chapter.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPS = \"world\", \"usa\"\n",
    "KINDS = \"deaths\", \"cases\"\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Run all cleaning and transformation steps\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary of DataFrames\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for group in GROUPS:\n",
    "        for kind in KINDS:\n",
    "            data[f'{group}_{kind}'] = read_local_data(group, kind, 'data/raw')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>8/7/22</th>\n",
       "      <th>8/8/22</th>\n",
       "      <th>8/9/22</th>\n",
       "      <th>8/10/22</th>\n",
       "      <th>8/11/22</th>\n",
       "      <th>8/12/22</th>\n",
       "      <th>8/13/22</th>\n",
       "      <th>8/14/22</th>\n",
       "      <th>8/15/22</th>\n",
       "      <th>8/16/22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>84090056</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>90056.0</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>84056043</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>56043.0</td>\n",
       "      <td>Washakie</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>43.904516</td>\n",
       "      <td>-107.680187</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>84056045</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>56045.0</td>\n",
       "      <td>Weston</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>43.839612</td>\n",
       "      <td>-104.567488</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 950 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           UID iso2 iso3  code3     FIPS      Admin2 Province_State  \\\n",
       "3339  84090056   US  USA    840  90056.0  Unassigned        Wyoming   \n",
       "3340  84056043   US  USA    840  56043.0    Washakie        Wyoming   \n",
       "3341  84056045   US  USA    840  56045.0      Weston        Wyoming   \n",
       "\n",
       "     Country_Region        Lat       Long_  ... 8/7/22  8/8/22  8/9/22  \\\n",
       "3339             US   0.000000    0.000000  ...      0       0       0   \n",
       "3340             US  43.904516 -107.680187  ...     46      46      47   \n",
       "3341             US  43.839612 -104.567488  ...     20      20      20   \n",
       "\n",
       "      8/10/22  8/11/22  8/12/22  8/13/22  8/14/22  8/15/22  8/16/22  \n",
       "3339        0        0        0        0        0        0        0  \n",
       "3340       47       47       47       47       47       47       47  \n",
       "3341       20       20       20       20       20       20       20  \n",
       "\n",
       "[3 rows x 950 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['usa_deaths'].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we verify that `run` works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from solutions import run\n",
    "# data = run()\n",
    "# data['usa_deaths'].tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the section on downloading the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
